{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "MODEL_NAME = \"nlp.model\"\n",
    "EPOCH = 10\n",
    "BATCHSIZE = 128\n",
    "LR = 0.0001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'to', 'go', 'out']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import contractions\n",
    "import requests\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, url_en, url_vi):\n",
    "        # function to preprocessing\n",
    "        self.__tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "        self.__tokenizer_vi = lambda text: list(map(lambda word: re.sub('_', ' ', word), tokenize(text).split()))\n",
    "\n",
    "        self.__check_dict = { # bổ xung\n",
    "            ' \\'s': '\\'s',\n",
    "            '& lt ;': '<',\n",
    "            '& gt ;': '>',\n",
    "            \"<[^<]+>\":'',\n",
    "            ' +': ' ',\n",
    "        }\n",
    "\n",
    "        #last run\n",
    "        self.__en_data = self.__load_data(url_en, 'en')\n",
    "        self.__vi_data = self.__load_data(url_vi, 'vi')\n",
    "\n",
    "    def __text_preprocessing(self, text: str, language: str = 'en'):\n",
    "        text = html.unescape(text)\n",
    "        for pattern, repl in self.__check_dict.items():\n",
    "            text = re.sub(pattern, repl, text)\n",
    "\n",
    "        if language == 'en':\n",
    "            text = contractions.fix(text)\n",
    "            return self.__tokenizer_en(text)\n",
    "\n",
    "        return self.__tokenizer_vi(text)\n",
    "\n",
    "    def __load_data(self, url, language: str):\n",
    "        return [self.__text_preprocessing(line, language) for line in requests.get(url).text.splitlines()]\n",
    "\n",
    "    @property\n",
    "    def vi(self):\n",
    "        return self.__vi_data\n",
    "\n",
    "    @property\n",
    "    def en(self):\n",
    "        return self.__en_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/\"\n",
    "\n",
    "train = DataLoader(url +'train.en',url +'train.vi')\n",
    "test = DataLoader(url + 'tst2013.en',url + 'tst2013.vi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ['Over', '15,000', 'scientists', 'go', 'to', 'San', 'Francisco', 'every', 'year', 'for', 'that', '.']\n",
      "10 ['Mỗi', 'năm', ',', 'hơn', '15,000', 'nhà', 'khoa học', 'đến', 'San Francisco', 'để', 'tham dự', 'hội nghị', 'này', '.']\n",
      "11 ['And', 'every', 'one', 'of', 'those', 'scientists', 'is', 'in', 'a', 'research', 'group', ',', 'and', 'every', 'research', 'group', 'studies', 'a', 'wide', 'variety', 'of', 'topics', '.']\n",
      "11 ['Mỗi một', 'khoa học', 'gia', 'đều', 'thuộc', 'một', 'nhóm', 'nghiên cứu', ',', 'và', 'mỗi', 'nhóm', 'đều', 'nghiên cứu', 'rất', 'nhiều', 'đề tài', 'đa dạng', '.']\n",
      "12 ['For', 'us', 'at', 'Cambridge', ',', 'it', 'is', 'as', 'varied', 'as', 'the', 'El', 'Niño', 'oscillation', ',', 'which', 'affects', 'weather', 'and', 'climate', ',', 'to', 'the', 'assimilation', 'of', 'satellite', 'data', ',', 'to', 'emissions', 'from', 'crops', 'that', 'produce', 'biofuels', ',', 'which', 'is', 'what', 'I', 'happen', 'to', 'study', '.']\n",
      "12 ['Với', 'chúng tôi', ',', 'tại', 'Cambridge', ',', 'các', 'đề tài', 'thay đổi', 'từ', 'sự', 'dao động', 'của', 'El Niño', ',', 'vốn', 'có', 'tác động', 'đến', 'thời tiết', 'và', 'khí hậu', ',', 'sự', 'đồng hoá', 'thông tin', 'từ', 'vệ tinh', ',', 'khí thải', 'từ', 'những', 'cánh', 'đồng', 'nhiên liệu', 'sinh học', ',', 'tình cờ', 'lại', 'là', 'đề tài', 'tôi', 'nghiên cứu', '.']\n",
      "13 ['And', 'in', 'each', 'one', 'of', 'these', 'research', 'areas', ',', 'of', 'which', 'there', 'are', 'even', 'more', ',', 'there', 'are', 'PhD', 'students', ',', 'like', 'me', ',', 'and', 'we', 'study', 'incredibly', 'narrow', 'topics', ',', 'things', 'as', 'narrow', 'as', 'a', 'few', 'processes', 'or', 'a', 'few', 'molecules', '.']\n",
      "13 ['Mỗi', 'lĩnh vực', 'nghiên cứu', 'lại', 'chia', 'ra', 'những', 'lĩnh vực', 'nhỏ', 'hơn', ',', 'và', 'những', 'nghiên cứu sinh', 'có', 'bằng', 'tiến sĩ', ',', 'như', 'tôi', ',', 'phải', 'nghiên cứu', 'những', 'đề tài', 'vô cùng', 'cụ thể', ',', 'cụ thể', 'như', 'chỉ', 'vài', 'quy trình', 'hay', 'vài', 'phân tử', '.']\n",
      "14 ['And', 'one', 'of', 'the', 'molecules', 'I', 'study', 'is', 'called', 'isoprene', ',', 'which', 'is', 'here', '.', 'It', 'is', 'a', 'small', 'organic', 'molecule', '.', 'You', \"'\", 've', 'probably', 'never', 'heard', 'of', 'it', '.']\n",
      "14 ['Một', 'trong', 'số', 'những', 'phân tử', 'tôi', 'nghiên cứu', 'tên', 'là', 'isoprene', '.', 'Đây', '.', 'Nó', 'là', 'một', 'phân tử', 'hữu cơ', 'nhỏ', '.', 'Có thể', 'các', 'bạn', 'cũng', 'chưa', 'từng', 'nghe', 'tên', '.']\n",
      "133317\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(i,train.en[i])\n",
    "    print(i,train.vi[i])\n",
    "\n",
    "print(len(train.en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Optional\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, train_iter: Iterator, min_freq:int = 1,specials: Optional[List[str]] = None, default_idx:int = 0):\n",
    "        self.__make_vocab(train_iter,min_freq,specials,default_idx)\n",
    "\n",
    "    def __yield_tokens(self, data):\n",
    "        for line in data:\n",
    "            yield line  \n",
    "\n",
    "    def __make_vocab(self, train_iter: Iterator, min_freq:int = 1,specials: Optional[List[str]] = None, default_idx:int = 0):\n",
    "        self.__vocab = build_vocab_from_iterator(self.__yield_tokens(train_iter), min_freq, specials)\n",
    "        self.__vocab.set_default_index(default_idx)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "\n",
    "    @property\n",
    "    def word2index(self):\n",
    "        return self.__vocab.get_stoi()\n",
    "\n",
    "    @property\n",
    "    def index2word(self):\n",
    "        return self.__vocab.get_itos()\n",
    "\n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self.__vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "\n",
    "Vi = Language(train.vi,3,specials,UNK_IDX)\n",
    "En = Language(train.en,3,specials,UNK_IDX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab.vocab import Vocab\n",
    "def data_preprocessing(data:List[List[str]],vocab:Vocab):\n",
    "    rr = []\n",
    "    idx2word = vocab.get_itos()\n",
    "    for line in data:\n",
    "        tkl = ['<sos>']\n",
    "        for word in line:\n",
    "            tkl.append(idx2word[vocab[word]])\n",
    "        tkl.append('<eos>')\n",
    "        rr.append(tkl)\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_prep = data_preprocessing(train.en, En.vocab)\n",
    "train_vi_prep = data_preprocessing(train.vi, Vi.vocab)\n",
    "test_en_prep = data_preprocessing(test.en, En.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'Rachel',\n",
       " 'Pike',\n",
       " ':',\n",
       " 'The',\n",
       " 'science',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'climate',\n",
       " 'headline',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en_prep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133317\n",
      "133317\n",
      "1268\n"
     ]
    }
   ],
   "source": [
    "print(len(train_en_prep))\n",
    "print(len(train_vi_prep))\n",
    "print(len(test_en_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133317"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(zip(train_en_prep, train_vi_prep))\n",
    "train_data.sort(key = lambda x: (len(x[0]), len(x[1])))\n",
    "test_data = list(zip(test_en_prep, test.en, test.vi))\n",
    "\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def make_batch(data:List[Tuple], batchsize:int):\n",
    "    bb = []\n",
    "    ben = []\n",
    "    bvi = []\n",
    "    for en, vi in data: \n",
    "        ben.append(en)\n",
    "        bvi.append(vi)\n",
    "        if len(ben) >= batchsize:\n",
    "            bb.append((ben, bvi))\n",
    "            ben = []\n",
    "            bvi = []\n",
    "    if len(ben) > 0:\n",
    "        bb.append((ben, bvi))\n",
    "    return bb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = make_batch(train_data, BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_batch(b):\n",
    "    maxlen = max([len(x) for x in b])\n",
    "    for tkl in b:\n",
    "        for i in range(maxlen - len(tkl)):\n",
    "            tkl.append('<pad>')\n",
    "\n",
    "def padding(bb):\n",
    "    for ben, bvi in bb:\n",
    "        padding_batch(ben)\n",
    "        padding_batch(bvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(data:List[List[str]], vocab: Vocab):\n",
    "    return [[vocab[word] for word in word_lst] for word_lst in data]\n",
    "\n",
    "train_data = [(text_pipeline(ben,En.vocab),text_pipeline(bvi,En.vocab)) for ben, bvi in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\19521204\\Jupyter\\NLP\\Machine Translator.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAttnDecoderRNN\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_size, output_size, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_length\u001b[39m=\u001b[39mMAX_LENGTH):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(AttnDecoderRNN, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;32md:\\19521204\\Jupyter\\NLP\\Machine Translator.ipynb Cell 25'\u001b[0m in \u001b[0;36mAttnDecoderRNN\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAttnDecoderRNN\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_size, output_size, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_length\u001b[39m=\u001b[39mMAX_LENGTH):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(AttnDecoderRNN, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/19521204/Jupyter/NLP/Machine%20Translator.ipynb#ch0000038?line=3'>4</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m hidden_size\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MAX_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "class AttnDecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length:int = 7):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = torch.nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = torch.nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_p)\n",
    "        self.gru = torch.nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "MODEL_NAME = \"nlp.model\"\n",
    "BATCHSIZE = 128\n",
    "LR = 0.0001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import contractions\n",
    "import requests\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, url_en:str, url_vi:str):\n",
    "        # function to preprocessing\n",
    "        DataLoader.__tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "        DataLoader.__tokenizer_vi = lambda text: list(map(lambda word: re.sub('_', ' ', word), tokenize(text).split()))\n",
    "\n",
    "        DataLoader.__check_dict = { # bổ xung\n",
    "            ' \\'s': '\\'s',\n",
    "            '& lt ;': '<',\n",
    "            '& gt ;': '>',\n",
    "            \"<[^<]+>\":'',\n",
    "            ' +': ' ',\n",
    "        }\n",
    "\n",
    "        #last run\n",
    "        self.__load_data(url_en, url_vi)\n",
    "\n",
    "    def __text_preprocessing(self, text: str, language: str = 'en'):\n",
    "        text = html.unescape(text)\n",
    "        for pattern, repl in DataLoader.__check_dict.items():\n",
    "            text = text.lower()\n",
    "            text = re.sub(pattern, repl, text)\n",
    "\n",
    "        if language == 'en':\n",
    "            text = contractions.fix(text)\n",
    "            return DataLoader.__tokenizer_en(text)\n",
    "\n",
    "        return DataLoader.__tokenizer_vi(text)\n",
    "\n",
    "    def __load_data(self, url_en:str, url_vi:str):\n",
    "        data_en = requests.get(url_en).text.strip().splitlines()\n",
    "        data_vi = requests.get(url_vi).text.strip().splitlines()\n",
    "        self.__en_data = []\n",
    "        self.__vi_data = []\n",
    "        for en,vi in zip(data_en,data_vi):\n",
    "            en = [\"<sos>\",*self.__text_preprocessing(en, 'en'), \"<eos>\"] \n",
    "            vi = [\"<sos>\",*self.__text_preprocessing(vi, 'vi'), \"<eos>\"] \n",
    "            if len(en) < 33 and len(vi) < 33:\n",
    "                self.__en_data.append(en)\n",
    "                self.__vi_data.append(vi)\n",
    "\n",
    "    @property\n",
    "    def vi(self):\n",
    "        return self.__vi_data\n",
    "\n",
    "    @property\n",
    "    def en(self):\n",
    "        return self.__en_data\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        '''return en_data, vi_data'''\n",
    "        return list(zip(self.__en_data,self.__vi_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/\"\n",
    "\n",
    "train = DataLoader(url +'train.en',url +'train.vi')\n",
    "val = DataLoader(url + 'tst2012.en',url + 'tst2012.vi')\n",
    "test = DataLoader(url + 'tst2013.en',url + 'tst2013.vi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: ['<sos>', 'rachel', 'pike', ':', 'the', 'science', 'behind', 'a', 'climate', 'headline', '<eos>']\n",
      "vi: ['<sos>', 'khoa học', 'đằng', 'sau', 'một', 'tiêu đề', 'về', 'khí hậu', '<eos>']\n",
      "en: ['<sos>', 'i', ' ', 'would', 'like', 'to', 'talk', 'to', 'you', 'today', 'about', 'the', 'scale', 'of', 'the', 'scientific', 'effort', 'that', 'goes', 'into', 'making', 'the', 'headlines', 'you', 'see', 'in', 'the', 'paper', '.', '<eos>']\n",
      "vi: ['<sos>', 'tôi', 'muốn', 'cho', 'các', 'bạn', 'biết', 'về', 'sự', 'to lớn', 'của', 'những', 'nỗ lực', 'khoa học', 'đã', 'góp phần', 'làm nên', 'các', 'dòng', 'tít', 'bạn', 'thường', 'thấy', 'trên', 'báo', '.', '<eos>']\n",
      "en: ['<sos>', 'they', 'are', 'both', 'two', 'branches', 'of', 'the', 'same', 'field', 'of', 'atmospheric', 'science', '.', '<eos>']\n",
      "vi: ['<sos>', 'cả', 'hai', 'đều', 'là', 'một', 'nhánh', 'của', 'cùng', 'một', 'lĩnh vực', 'trong', 'ngành', 'khoa học', 'khí quyển', '.', '<eos>']\n",
      "en: ['<sos>', 'that', 'report', 'was', 'written', 'by', '620', 'scientists', 'from', '40', 'countries', '.', '<eos>']\n",
      "vi: ['<sos>', 'nghiên cứu', 'được', 'viết', 'bởi', '620', 'nhà', 'khoa học', 'từ', '40', 'quốc gia', 'khác', 'nhau', '.', '<eos>']\n",
      "en: ['<sos>', 'they', 'wrote', 'almost', 'a', 'thousand', 'pages', 'on', 'the', 'topic', '.', '<eos>']\n",
      "vi: ['<sos>', 'họ', 'viết', 'gần', '1000', 'trang', 'về', 'chủ đề', 'này', '.', '<eos>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(105184, 1319, 957)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for en,vi in train.data[:5]:\n",
    "    print(f\"en: {en}\")\n",
    "    print(f\"vi: {vi}\")\n",
    "    \n",
    "len(train.data),len(val.data),len(test.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import List\n",
    "class Language:\n",
    "    def __init__(self, train_iter: Iterator, min_freq:int = 1):\n",
    "        Language.specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "        self.__make_vocab(train_iter,min_freq)\n",
    "    def __yield_tokens(self, data):\n",
    "        for line in data:\n",
    "            yield line  \n",
    "\n",
    "    def __make_vocab(self, train_iter: Iterator, min_freq:int = 5):\n",
    "        self.__vocab = build_vocab_from_iterator(self.__yield_tokens(train_iter), min_freq, self.specials)\n",
    "        self.__vocab.set_default_index(0)\n",
    "    \n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self.__vocab\n",
    "    \n",
    "    def sentence_to_vector(self, sent:List[str]):\n",
    "        return torch.tensor(self.__vocab.lookup_indices(sent),dtype = torch.int64,device=DEVICE)\n",
    "    \n",
    "    def vector_to_sentence(self, vector:List[int]):\n",
    "        return self.__vocab.lookup_tokens(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "Vi = Language(train.vi,3)\n",
    "En = Language(train.en,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12131"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vi.vocab.get_itos())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15931"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(En.vocab.get_itos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = [En.sentence_to_vector(line) for line in train.en]\n",
    "train_vi = [Vi.sentence_to_vector(line) for line in train.vi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: ['<sos>', 'rachel', 'pike', ':', 'the', 'science', 'behind', 'a', 'climate', 'headline', '<eos>']\n",
      "vi: ['<sos>', 'khoa học', 'đằng', 'sau', 'một', 'tiêu đề', 'về', 'khí hậu', '<eos>']\n",
      "en: ['<sos>', 'i', ' ', 'would', 'like', 'to', 'talk', 'to', 'you', 'today', 'about', 'the', 'scale', 'of', 'the', 'scientific', 'effort', 'that', 'goes', 'into', 'making', 'the', 'headlines', 'you', 'see', 'in', 'the', 'paper', '.', '<eos>']\n",
      "vi: ['<sos>', 'tôi', 'muốn', 'cho', 'các', 'bạn', 'biết', 'về', 'sự', 'to lớn', 'của', 'những', 'nỗ lực', 'khoa học', 'đã', 'góp phần', 'làm nên', 'các', 'dòng', 'tít', 'bạn', 'thường', 'thấy', 'trên', 'báo', '.', '<eos>']\n",
      "en: ['<sos>', 'they', 'are', 'both', 'two', 'branches', 'of', 'the', 'same', 'field', 'of', 'atmospheric', 'science', '.', '<eos>']\n",
      "vi: ['<sos>', 'cả', 'hai', 'đều', 'là', 'một', 'nhánh', 'của', 'cùng', 'một', 'lĩnh vực', 'trong', 'ngành', 'khoa học', 'khí quyển', '.', '<eos>']\n",
      "en: ['<sos>', 'that', 'report', 'was', 'written', 'by', '620', 'scientists', 'from', '40', 'countries', '.', '<eos>']\n",
      "vi: ['<sos>', 'nghiên cứu', 'được', 'viết', 'bởi', '620', 'nhà', 'khoa học', 'từ', '40', 'quốc gia', 'khác', 'nhau', '.', '<eos>']\n",
      "en: ['<sos>', 'they', 'wrote', 'almost', 'a', 'thousand', 'pages', 'on', 'the', 'topic', '.', '<eos>']\n",
      "vi: ['<sos>', 'họ', 'viết', 'gần', '1000', 'trang', 'về', 'chủ đề', 'này', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "for en,vi in zip(train_en[:5],train_vi[:5]):\n",
    "    print(f\"en: {En.vector_to_sentence(en.tolist())}\")\n",
    "    print(f\"vi: {Vi.vector_to_sentence(vi.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "train_en = pad_sequence(train_en,batch_first= True,padding_value=UNK_IDX)\n",
    "train_vi = pad_sequence(train_vi,batch_first= True,padding_value=UNK_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_en, train_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader as dl\n",
    "train_data = list(dl(train_data,batch_size=BATCHSIZE,shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self,num_emb_x,num_emb_y):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.Enc_emb = torch.nn.Embedding(num_emb_x, 300, padding_idx=PAD_IDX)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.enclstm = torch.nn.LSTM(300,516,2,dropout=0.2)\n",
    "        \n",
    "        self.Dec_emb = torch.nn.Embedding(num_emb_x, 300, padding_idx = PAD_IDX)\n",
    "        self.declstm = torch.nn.LSTM(300,516,2,dropout=0.2)\n",
    "        self.decout = torch.nn.Linear(516, num_emb_y)\n",
    "\n",
    "    def forward(self,src:torch.Tensor,tgt:torch.Tensor):\n",
    "        #enc\n",
    "        e_x = self.dropout(self.Enc_emb(src))\n",
    "        n_x = e_x.size()[0]\n",
    "        h = torch.zeros(300, dtype=torch.float32).to(DEVICE)\n",
    "        for i in range(n_x):\n",
    "            h = F.relu(e_x[i] + self.enclstm(h))\n",
    "\n",
    "        #dec\n",
    "        e_y = self.dropout(self.Dec_emb(tgt))\n",
    "        n_y = e_y.size()[0]\n",
    "        loss = torch.tensor(0., dtype=torch.float32).to(DEVICE)\n",
    "        for i in range(n_y-1):\n",
    "            h = F.relu(e_y[i] + self.declstm(h))\n",
    "            loss += F.cross_entropy(self.decout(h), tgt[i+1])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, src:torch.Tensor) -> List[int]:\n",
    "        \n",
    "        e_x = self.Enc_emb(src)\n",
    "        n_x = e_x.size()[0]\n",
    "        h = torch.zeros(300, dtype=torch.float32).to(DEVICE)\n",
    "        for i in range (n_x):\n",
    "            h = F.relu(e_x[i] + self.enclstm(h))\n",
    "\n",
    "        y = torch.tensor([SOS_IDX]).to(DEVICE)\n",
    "        e_y = self.Dec_emb(y)\n",
    "        pred = []\n",
    "        for i in range(33):\n",
    "            h = F.relu(e_y + self.declstm(h))\n",
    "            pred_id = self.decout(h).squeeze().argmax()\n",
    "            if pred_id == EOS_IDX:\n",
    "                break\n",
    "\n",
    "            pred.append(pred_id)\n",
    "            y[0] = pred_id\n",
    "            e_y =self.Dec_emb(y)\n",
    "\n",
    "        return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = LSTM(len(En.vocab.get_itos()),len(En.vocab.get_itos())).to(DEVICE)\n",
    "    optmizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "    EPOCH = 10 # len(train_data) / BATCHSIZE\n",
    "    for epoch in range(EPOCH):\n",
    "        loss = 0\n",
    "        for ben,bvi in train_data:\n",
    "            ben = torch.tensor(ben).transpose(0,1).to(DEVICE)\n",
    "            bvi = torch.tensor(bvi).transpose(0,1).to(DEVICE)\n",
    "            optmizer.zero_grad()\n",
    "            batch_loss = model((ben,bvi))\n",
    "            batch_loss.backward()\n",
    "            optmizer.step()\n",
    "\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "        print(f'epoch: {epoch}  loss: {loss}')\n",
    "    torch.save(model.state_dict(),MODEL_NAME)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
